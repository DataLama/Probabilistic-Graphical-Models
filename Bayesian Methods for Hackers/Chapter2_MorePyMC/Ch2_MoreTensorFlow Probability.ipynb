{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 내용은 [tensorflow probability](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter2_MorePyMC/Ch2_MorePyMC_TFP.ipynb)를 기반으로 정리함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow-probability\n",
    "- tf 2.2 & tfp 0.10 을 기본 버전으로 사용함.\n",
    "- 데이터 시각화는 plotly를 사용하여 구현함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "0.10.0\n"
     ]
    }
   ],
   "source": [
    "## Basics\n",
    "from __future__ import absolute_import, division, print_function\n",
    "warning_status = \"ignore\" #@param [\"ignore\", \"always\", \"module\", \"once\", \"default\", \"error\"]\n",
    "import warnings\n",
    "warnings.filterwarnings(warning_status)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(warning_status, category=DeprecationWarning)\n",
    "    warnings.filterwarnings(warning_status, category=UserWarning)\n",
    "    \n",
    "## python packages\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "## visualization packages\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import iplot\n",
    "\n",
    "## import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "## Color map\n",
    "class _TFColor(object):\n",
    "    \"\"\"Enum of colors used in TF docs.\"\"\"\n",
    "    red = '#F15854'\n",
    "    blue = '#5DA5DA'\n",
    "    orange = '#FAA43A'\n",
    "    green = '#60BD68'\n",
    "    pink = '#F17CB0'\n",
    "    brown = '#B2912F'\n",
    "    purple = '#B276B2'\n",
    "    yellow = '#DECF3F'\n",
    "    gray = '#4D4D4D'\n",
    "    def __getitem__(self, i):\n",
    "        return [\n",
    "            self.red,\n",
    "            self.orange,\n",
    "            self.green,\n",
    "            self.blue,\n",
    "            self.pink,\n",
    "            self.brown,\n",
    "            self.purple,\n",
    "            self.yellow,\n",
    "            self.gray,\n",
    "        ][i % 9]\n",
    "TFColor = _TFColor()\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tfp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usage of XLA(Accelerated Linear Algebra)**\n",
    "\n",
    "- XLA is a domain-specific compiler for linear algebra that optimizes Tensorflow computations.\n",
    "- tensor 연산을 하는 파이썬 함수에 아래와 같은 `tf.function` 데코레이터를 사용하면 됨.\n",
    "```python\n",
    "@tf.function(experimental_compile=True)\n",
    "def train_mnist(images, labels):\n",
    "    images, labels = cast(images, labels)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted_labels = layer(images)\n",
    "        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "          logits=predicted_labels, labels=labels\n",
    "        ))\n",
    "    layer_variables = layer.trainable_variables\n",
    "    grads = tape.gradient(loss, layer_variables)\n",
    "    optimizer.apply_gradients(zip(grads, layer_variables))\n",
    "```\n",
    "- [mnist 예시에 대하여 xla 성능 실험](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/g3doc/tutorials/compile.ipynb)\n",
    "    - `TRAIN_STEPS=10000` with 2019 macbook AIR\n",
    "    - tf2 $\\longrightarrow$ 97초\n",
    "    - tf2 with xla $\\longrightarrow$ 37초\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 서론\n",
    "tensorflow-probability 재구성함.\n",
    "## 2.1.1 부모와 자식관계\n",
    "베이지안 확률론에서 랜덤변수(Random Variable)들 간의 관계는 부모와 자식 간의 관계로 설명할 수 있다.\n",
    "- **부모변수**는 다른 랜덤변수에 영향을 주는 랜덤변수다.\n",
    "- **자식변수**는 다른 랜덤변수에 영향을 받는 랜덤변수다. 즉, 부모변수에 종속되는(dependent) 랜덤변수다.\n",
    "- 모든 변수는 부모변수와 동시에 자식변수가 될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤변수들 간의 관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of sample from data generator random variable\n",
      "\n",
      " tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "\n",
      "data_generator plus one\n",
      "\n",
      " tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "rv_lambda_ = tfd.Exponential(rate=1., name='poisson_param')\n",
    "lambda_ = rv_lambda_.sample()\n",
    "rv_data_generator = tfd.Poisson(lambda_, name='data_generator')\n",
    "data_generator = rv_data_generator.sample()\n",
    "print(\"Value of sample from data generator random variable\\n\\n\", data_generator)\n",
    "print()\n",
    "data_plus_one = data_generator + 1\n",
    "print(\"data_generator plus one\\n\\n\", data_plus_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `rv_lambda_` $\\longrightarrow$ `rv_data_genrator`\n",
    "    - `rv_lambda_`은 `data_genrator`의 파라미터(모수)를 좌우하므로 `rv_data_genrator`의 부모변수다.\n",
    "    - 반대로 `rv_data_genrator`은 `rv_lambda_`의 자식변수다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `rv_data_genrator` $\\longrightarrow$ `data_plus_one`의 형태를 tfp.distribution의 형태로 정의할 수 있나?\n",
    "- tfp에서 부모, 자식 간의 랜덤 변수 관계를 명시적으로 표현할 수 있나?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 The variables of TensorFlow Probability\n",
    "\n",
    "### TFP Distributions\n",
    "\n",
    "- stochastic 변수\n",
    "    - `tfp.distributions`에 대한 subclass들을 호라용해서 stochastic한 random variable들을 표현함.\n",
    "    - `Poisson`, `Uniform`, `Exponential` 등이 있음.\n",
    "- deterministic 변수\n",
    "    - stochastic 변수에서 random하게 sample된 변수들.\n",
    "    - tfp에서는 `tf.Tensors`임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing a Distribution (stochastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_distribution = tfd.Uniform(low=0., high=4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.3115563>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_distribution.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing a Distribution (determistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_1 = tfd.Exponential(rate=1., name=\"lambda_1\") #stochastic variable\n",
    "lambda_2 = tfd.Exponential(rate=1., name=\"lambda_2\") #stochastic variable\n",
    "tau = tfd.Uniform(name=\"tau\", low=0., high=10.) #stochastic variable\n",
    "\n",
    "# deterministic variable since we are getting results of lambda's after sampling    \n",
    "new_deterministic_variable = tfd.Deterministic(name=\"deterministic_variable\", \n",
    "                                               loc=(lambda_1.sample() + lambda_2.sample()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.0690525>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_deterministic_variable.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the deterministic variable was seen in the previous chapter's text-message example.  Recall the model for $\\lambda$ looked like: \n",
    "\n",
    "$$\n",
    "\\lambda = \n",
    "\\begin{cases}\\lambda_1  & \\text{if } t \\lt \\tau \\cr\n",
    "\\lambda_2 & \\text{if } t \\ge \\tau\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "And in TFP code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cast() missing 1 required positional argument: 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-174be10da282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m rv_lambda_deterministic = tfd.Deterministic(tf.gather([lambda_1.sample(), lambda_2.sample()],\n\u001b[1;32m      8\u001b[0m                     indices=tf.cast(\n\u001b[0;32m----> 9\u001b[0;31m                         tau.sample() >= idx)))\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mlambda_deterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrv_lambda_deterministic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cast() missing 1 required positional argument: 'dtype'"
     ]
    }
   ],
   "source": [
    "# Build graph\n",
    "\n",
    "# days\n",
    "n_data_points = 5  # in CH1 we had ~70 data points\n",
    "idx = np.arange(n_data_points)\n",
    "# for n_data_points samples, select from lambda_2 if sampled tau >= day value, lambda_1 otherwise\n",
    "rv_lambda_deterministic = tfd.Deterministic(tf.gather([lambda_1.sample(), lambda_2.sample()],\n",
    "                    indices=tf.to_int32(\n",
    "                        tau.sample() >= idx)))\n",
    "lambda_deterministic = rv_lambda_deterministic.sample()\n",
    "\n",
    "# Execute graph\n",
    "[lambda_deterministic_] = evaluate([lambda_deterministic])\n",
    "\n",
    "# Show results\n",
    "\n",
    "print(\"{} samples from our deterministic lambda model: \\n\".format(n_data_points), lambda_deterministic_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, if $\\tau, \\lambda_1$ and $\\lambda_2$ are known, then $\\lambda$ is known completely, hence it is a deterministic variable. We use indexing here to switch from $\\lambda_1$ to $\\lambda_2$ at the appropriate time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
